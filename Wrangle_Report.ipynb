{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: wrangle_report\n",
    "\n",
    "This report describes the wrangling effort carried out for the Wrangle Act Project.\n",
    "\n",
    "The Wrangle Act project objective is to gathered data from three different sources, assessed, cleaned and merged the three cleaned datasets into a master data table. Also, made some analysis to get insights and made some visualizations so as to communicate some of our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrangling process started with the first dataset. The first dataset, called \"twitter_archive_enhanced.csv\", was collected by importing the CSV file containing the raw data from my local computer. This csv file is provided by Udacity. A second dataset, \"tweet_json.csv\", was collected by using the Tweepy library to query the Twitter API and write the content into a local CSV file. This file will be imported into a dataframe to use for this analysis. A third dataset, \"image_predictions.tsv\", was collected from the Udacity server by collecting data over the internet from the Udacity server using the requirements library. This is possible because a third-party has already gatthered the image predictions data through a neural network and provided it to Udacity which was then made available for our use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assessment:\n",
    "\n",
    "After the three datasets were gathered, they were then imported to three different pandas dataframes for visual assessment after which some quality and tidiness issues were discovered and documented as visual assessment observations. After this, a programmatic assessment was carried out on each dataset which exposed more quality and tidiness issues as well which were all documented as observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "As the data evaluation process revealed a number of quality and tideness issues, we created a list of issues to be addressed, selecting from those observed in the evaluation step. To prepare a workflow that is easy to read and understand, we placed each selected issue under the name of the data set to which they belong. The cleaned dataset and a copy of each raw dataset are saved and all three datasets are merged into one dataset called twitter_archive_master.csv which is then used for further data exploration and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Visualizations:\n",
    "\n",
    "In this section, I listed some six questions which are related to what the dataset is all about. These questions guided me to make some exploratory efforts to answer each of the questions. The answers to the stated analysis questions provided needed insights for as required. These insights were also used to generate some visualizations as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
